{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras as tfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get limit order book data \n",
    "orderbook = pd.read_csv('/Users/tanvipotdar/Projects/LOBster/data_tqap/INTC_2015-01-01_2015-01-31_10/INTC_2015-01-02_34200000_57600000_orderbook_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_price_8</th>\n",
       "      <th>bid_size_8</th>\n",
       "      <th>ask_price_9</th>\n",
       "      <th>ask_size_9</th>\n",
       "      <th>bid_price_9</th>\n",
       "      <th>bid_size_9</th>\n",
       "      <th>ask_price_10</th>\n",
       "      <th>ask_size_10</th>\n",
       "      <th>bid_price_10</th>\n",
       "      <th>bid_size_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.063739</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.063739</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.816904</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.885917</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-1.092996</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.114857</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>-1.984987</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437242</td>\n",
       "      <td>-0.872724</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.782372</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.851389</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.154853</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402727</td>\n",
       "      <td>-0.894391</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.402710</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402727</td>\n",
       "      <td>-0.894391</td>\n",
       "      <td>2.450812</td>\n",
       "      <td>-0.888307</td>\n",
       "      <td>-0.402710</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "0     0.796834   -0.070811     0.114857   -1.063739     0.831288   -1.895349   \n",
       "1     0.796834   -0.070811     0.114857   -1.063739     0.831288   -1.895349   \n",
       "2     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "3     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "4     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "5     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "6     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "7     0.796834   -0.070811     0.114857   -1.154853     0.831288   -1.895349   \n",
       "8     0.796834   -0.070811     0.632554   -1.154853     0.831288   -1.895349   \n",
       "9     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "\n",
       "   bid_price_2  bid_size_2  ask_price_3  ask_size_3  ...  bid_price_8  \\\n",
       "0     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "1     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "2     0.011343   -1.984987     0.934676   -1.788479  ...    -0.816904   \n",
       "3     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "4     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "5     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "6     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "7     0.011343   -1.984987     0.934676   -1.788479  ...    -0.437242   \n",
       "8     0.149397   -2.053207     0.934676   -1.788479  ...    -0.402727   \n",
       "9     0.149397   -2.053207     0.934676   -1.788479  ...    -0.402727   \n",
       "\n",
       "   bid_size_8  ask_price_9  ask_size_9  bid_price_9  bid_size_9  ask_price_10  \\\n",
       "0   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "1   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "2   -0.872724     2.450812   -0.888307    -0.885917   -1.164202       2.58852   \n",
       "3   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "4   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "5   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "6   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "7   -0.872724     2.450812   -0.888307    -0.782372   -1.164202       2.58852   \n",
       "8   -0.894391     2.450812   -0.888307    -0.402710   -1.164202       2.58852   \n",
       "9   -0.894391     2.450812   -0.888307    -0.402710   -1.164202       2.58852   \n",
       "\n",
       "   ask_size_10  bid_price_10  bid_size_10  \n",
       "0    -0.313841     -1.092996    -1.491542  \n",
       "1    -0.313841     -1.092996    -1.491542  \n",
       "2    -0.313841     -1.092996    -1.491542  \n",
       "3    -0.313841     -0.851389    -1.491542  \n",
       "4    -0.313841     -0.851389    -1.491542  \n",
       "5    -0.313841     -0.851389    -1.491542  \n",
       "6    -0.313841     -0.851389    -1.491542  \n",
       "7    -0.313841     -0.851389    -1.491542  \n",
       "8    -0.313841     -0.747843    -1.491542  \n",
       "9    -0.313841     -0.747843    -1.491542  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalise the data\n",
    "from scipy.stats import zscore\n",
    "normalised_data = orderbook.apply(zscore)\n",
    "normalised_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the midprice\n",
    "normalised_data['midprice'] = (normalised_data.ask_price_1+normalised_data.bid_price_1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoothed labelling of the midprice/ k is the prediction horizon\n",
    "k = 10\n",
    "# mean of previous k mid-prices\n",
    "normalised_data['m_minus'] = normalised_data['midprice'].rolling(window=k).mean()\n",
    "# mean of next k mid-prices\n",
    "normalised_data['m_plus'] = normalised_data['midprice'][::-1].rolling(window=k).mean()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ask_price_1</th>\n",
       "      <th>ask_size_1</th>\n",
       "      <th>bid_price_1</th>\n",
       "      <th>bid_size_1</th>\n",
       "      <th>ask_price_2</th>\n",
       "      <th>ask_size_2</th>\n",
       "      <th>bid_price_2</th>\n",
       "      <th>bid_size_2</th>\n",
       "      <th>ask_price_3</th>\n",
       "      <th>ask_size_3</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size_9</th>\n",
       "      <th>ask_price_10</th>\n",
       "      <th>ask_size_10</th>\n",
       "      <th>bid_price_10</th>\n",
       "      <th>bid_size_10</th>\n",
       "      <th>midprice</th>\n",
       "      <th>m_minus</th>\n",
       "      <th>m_plus</th>\n",
       "      <th>change</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.507615</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.407945</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.339633</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.124482</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.559385</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.277643</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.094110</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164202</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.747843</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.221136</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.796834</td>\n",
       "      <td>-0.070811</td>\n",
       "      <td>0.632554</td>\n",
       "      <td>-1.094110</td>\n",
       "      <td>0.831288</td>\n",
       "      <td>-1.895349</td>\n",
       "      <td>0.149397</td>\n",
       "      <td>-2.053207</td>\n",
       "      <td>0.934676</td>\n",
       "      <td>-1.788479</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.197339</td>\n",
       "      <td>2.58852</td>\n",
       "      <td>-0.313841</td>\n",
       "      <td>-0.368176</td>\n",
       "      <td>-1.491542</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.611155</td>\n",
       "      <td>0.714694</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ask_price_1  ask_size_1  bid_price_1  bid_size_1  ask_price_2  ask_size_2  \\\n",
       "9      0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "10     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "11     0.796834   -0.070811     0.632554   -1.124482     0.831288   -1.895349   \n",
       "12     0.796834   -0.070811     0.632554   -1.094110     0.831288   -1.895349   \n",
       "13     0.796834   -0.070811     0.632554   -1.094110     0.831288   -1.895349   \n",
       "\n",
       "    bid_price_2  bid_size_2  ask_price_3  ask_size_3  ...  bid_size_9  \\\n",
       "9      0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "10     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "11     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "12     0.149397   -2.053207     0.934676   -1.788479  ...   -1.164202   \n",
       "13     0.149397   -2.053207     0.934676   -1.788479  ...   -1.197339   \n",
       "\n",
       "    ask_price_10  ask_size_10  bid_price_10  bid_size_10  midprice   m_minus  \\\n",
       "9        2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.507615   \n",
       "10       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.533500   \n",
       "11       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.559385   \n",
       "12       2.58852    -0.313841     -0.747843    -1.491542  0.714694  0.585270   \n",
       "13       2.58852    -0.313841     -0.368176    -1.491542  0.714694  0.611155   \n",
       "\n",
       "      m_plus    change  label  \n",
       "9   0.714694  0.407945     up  \n",
       "10  0.714694  0.339633     up  \n",
       "11  0.714694  0.277643     up  \n",
       "12  0.714694  0.221136     up  \n",
       "13  0.714694  0.169416     up  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label the smoothed mid-prices based on a threshold/ alpha is the threshold \n",
    "alpha = 0.0001\n",
    "normalised_data['change'] = (normalised_data.m_plus - normalised_data.m_minus)/normalised_data.m_minus\n",
    "# assign categories up, down, stationary\n",
    "normalised_data['label'] = pd.cut(normalised_data.change, bins=[-np.inf, -alpha, alpha, np.inf], \n",
    "                                  labels=['down', 'stationary', 'up'])\n",
    "# drop all unlabelled values (will be first and last k values as they have no m_minus/m_plus value)\n",
    "normalised_data.dropna(inplace=True)\n",
    "normalised_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.79683389],\n",
       "         [-0.070811  ],\n",
       "         [ 0.63255445],\n",
       "         ...,\n",
       "         [-0.31384099],\n",
       "         [-0.74784332],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        [[ 0.79683389],\n",
       "         [-0.070811  ],\n",
       "         [ 0.63255445],\n",
       "         ...,\n",
       "         [-0.31384099],\n",
       "         [-0.74784332],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        [[ 0.79683389],\n",
       "         [-0.070811  ],\n",
       "         [ 0.63255445],\n",
       "         ...,\n",
       "         [-0.31384099],\n",
       "         [-0.74784332],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.11485709],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.16108448],\n",
       "         [-1.38236296]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.11485709],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.16108448],\n",
       "         [-1.38236296]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.11485709],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.16108448],\n",
       "         [-1.38236296]]],\n",
       "\n",
       "\n",
       "       [[[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.11485709],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.16108448],\n",
       "         [-1.38236296]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.11485709],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.16108448],\n",
       "         [-1.38236296]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.27175119],\n",
       "         [ 0.21839656],\n",
       "         ...,\n",
       "         [-0.91119984],\n",
       "         [-0.12656926],\n",
       "         [-1.54613186]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.2401475 ],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.88404716],\n",
       "         [ 0.28761345],\n",
       "         [-1.2731837 ]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.2401475 ],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.88404716],\n",
       "         [ 0.28761345],\n",
       "         [-1.2731837 ]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.2401475 ],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.88404716],\n",
       "         [ 0.28761345],\n",
       "         [-1.2731837 ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.69343383],\n",
       "         [-1.2401475 ],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.88404716],\n",
       "         [ 0.32212868],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        [[ 0.65896714],\n",
       "         [-1.2401475 ],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.98858496],\n",
       "         [ 0.32212868],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        [[ 0.65896714],\n",
       "         [-1.20854381],\n",
       "         [ 0.52901498],\n",
       "         ...,\n",
       "         [-0.98858496],\n",
       "         [ 0.32212868],\n",
       "         [-1.49154223]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.20854381],\n",
       "         [ 0.56352813],\n",
       "         ...,\n",
       "         [-0.96550519],\n",
       "         [ 0.39115913],\n",
       "         [-1.40965778]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.20854381],\n",
       "         [ 0.56352813],\n",
       "         ...,\n",
       "         [-0.96550519],\n",
       "         [ 0.39115913],\n",
       "         [-1.40965778]],\n",
       "\n",
       "        [[ 0.69343383],\n",
       "         [-1.20854381],\n",
       "         [ 0.56352813],\n",
       "         ...,\n",
       "         [-0.96550519],\n",
       "         [ 0.39115913],\n",
       "         [-1.40965778]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[-0.4784335 ],\n",
       "         [-0.33881029],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.33881029],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.33881029],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.14760797],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.14760797],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.21081535],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.4784335 ],\n",
       "         [-0.24241903],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.24241903],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.30562641],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.60807372],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.63588496],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.63588496],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.4784335 ],\n",
       "         [-0.69909234],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.69909234],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.76229972],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.39529902],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.27939535],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.27939535],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]],\n",
       "\n",
       "        [[-0.4784335 ],\n",
       "         [-0.27939535],\n",
       "         [-0.47186658],\n",
       "         ...,\n",
       "         [-0.42245169],\n",
       "         [-0.47172151],\n",
       "         [-0.0722118 ]]]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get input and output train and test data\n",
    "data = normalised_data[:887600]\n",
    "\n",
    "cols = data.columns.to_list()[:40]\n",
    "input_data = data[cols]\n",
    "input_array = input_data.to_numpy().reshape(8876,100,40,1)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "output_data = data.label.to_numpy()[::-100][::-1]\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = output_data.reshape(len(output_data), 1)\n",
    "output_array = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_array, output_array, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_355 (Conv2D)          (None, 100, 20, 16)       48        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_143 (LeakyReLU)  (None, 100, 20, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_356 (Conv2D)          (None, 100, 10, 16)       528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_144 (LeakyReLU)  (None, 100, 10, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_357 (Conv2D)          (None, 100, 1, 16)        2576      \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 100, 16)           0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 24,083\n",
      "Trainable params: 24,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# convolutional layers\n",
    "model = tfk.Sequential()\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,2), input_shape=(100,40,1), strides=(1, 2)))\n",
    "model.add(tfk.layers.LeakyReLU(alpha=0.01))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,2), strides=(1, 2)))\n",
    "model.add(tfk.layers.LeakyReLU(alpha=0.01))\n",
    "model.add(tfk.layers.Conv2D(filters=16, kernel_size=(1,10), input_shape=(100,10,1)))\n",
    "model.add(tfk.layers.TimeDistributed(tfk.layers.Flatten()))\n",
    "\n",
    "# lstm layer\n",
    "model.add(tfk.layers.LSTM(64))\n",
    "model.add(tfk.layers.Dense(3,activation='softmax'))\n",
    "\n",
    "# compile model and summarize\n",
    "adam = tfk.optimizers.Adam(lr=0.01, epsilon=1)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.6736 - acc: 0.8583\n",
      "Epoch 2/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.5055 - acc: 0.8659\n",
      "Epoch 3/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4956 - acc: 0.8659\n",
      "Epoch 4/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4920 - acc: 0.8659\n",
      "Epoch 5/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4897 - acc: 0.8659\n",
      "Epoch 6/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4880 - acc: 0.8659\n",
      "Epoch 7/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4868 - acc: 0.8659\n",
      "Epoch 8/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4859 - acc: 0.8659\n",
      "Epoch 9/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4851 - acc: 0.8659\n",
      "Epoch 10/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4843 - acc: 0.8659\n",
      "Epoch 11/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4836 - acc: 0.8659\n",
      "Epoch 12/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4831 - acc: 0.8659\n",
      "Epoch 13/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4824 - acc: 0.8659\n",
      "Epoch 14/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4819 - acc: 0.8659\n",
      "Epoch 15/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4814 - acc: 0.8659\n",
      "Epoch 16/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4808 - acc: 0.8659\n",
      "Epoch 17/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4804 - acc: 0.8659\n",
      "Epoch 18/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4799 - acc: 0.8659\n",
      "Epoch 19/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4797 - acc: 0.8659\n",
      "Epoch 20/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4790 - acc: 0.8659\n",
      "Epoch 21/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4787 - acc: 0.8659\n",
      "Epoch 22/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4781 - acc: 0.8659\n",
      "Epoch 23/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4777 - acc: 0.8659\n",
      "Epoch 24/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4773 - acc: 0.8659\n",
      "Epoch 25/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4768 - acc: 0.8659\n",
      "Epoch 26/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4763 - acc: 0.8659\n",
      "Epoch 27/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4758 - acc: 0.8659\n",
      "Epoch 28/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4753 - acc: 0.8659\n",
      "Epoch 29/100\n",
      "6657/6657 [==============================] - 7s 1ms/sample - loss: 0.4748 - acc: 0.8659\n",
      "Epoch 30/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4742 - acc: 0.8659\n",
      "Epoch 31/100\n",
      "6657/6657 [==============================] - 8s 1ms/sample - loss: 0.4737 - acc: 0.8659\n",
      "Epoch 32/100\n",
      "6657/6657 [==============================] - 9s 1ms/sample - loss: 0.4731 - acc: 0.8659\n",
      "Epoch 33/100\n",
      "6657/6657 [==============================] - 10s 2ms/sample - loss: 0.4724 - acc: 0.8659\n",
      "Epoch 34/100\n",
      "6200/6657 [==========================>...] - ETA: 0s - loss: 0.4686 - acc: 0.8673"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 100\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
